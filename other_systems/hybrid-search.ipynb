{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Hybrid Search"]},{"cell_type":"markdown","metadata":{},"source":["## 0. Define Hybrid Retriever\n","\n","> Hybrid Retriever: BM25 + Vector Retriever"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment if needed to choose GPU\n","# import os\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","# import setproctitle\n","# setproctitle.setproctitle(\"python\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class HybridRetriever:\n","    def __init__(self, bm25_retriever, vector_retriever, alpha=0.5):\n","        self.bm25_retriever = bm25_retriever\n","        self.vector_retriever = vector_retriever\n","        self.alpha = alpha\n","\n","    def process_nodes(self, nodes):\n","        # Normalize relevance scores and return the nodes in dict format.\n","        scores: list[float] = [node.score for node in nodes]\n","        max_score = max(scores)\n","        min_score = min(scores)\n","        \n","        processed_nodes = {}\n","        for node in nodes:\n","            if min_score == max_score:\n","                node.score = 1\n","            else:\n","                node.score = (node.score - min_score) / (max_score - min_score)\n","            processed_nodes[node.id_] = node\n","        return processed_nodes\n","\n","    def retrieve(self, query, top_k=10):\n","        # 1. Change the top_k of the retrievers\n","        self.vector_retriever.similarity_top_k = top_k\n","        self.bm25_retriever.similarity_top_k = top_k\n","\n","        # 2. Use both retrievers to get top-k results + normalization\n","        bm25_nodes = self.process_nodes(self.bm25_retriever.retrieve(query))\n","        vector_nodes = self.process_nodes(self.vector_retriever.retrieve(query))\n","\n","        # 3. Linearly combine the scores of each node\n","        node_ids = set(list(bm25_nodes.keys()) + list(vector_nodes.keys()))\n","        all_nodes = []\n","        for node_id in node_ids:\n","            try:\n","                bm25_score = bm25_nodes.get(node_id).score\n","            except:\n","                bm25_score = 0.0\n","            try:\n","                cosine_score = vector_nodes.get(node_id).score\n","            except:\n","                cosine_score = 0.0\n","            combined_score = self.alpha * bm25_score + (1 - self.alpha) * cosine_score\n","            node = bm25_nodes.get(node_id, vector_nodes.get(node_id))\n","            node.score = combined_score\n","\n","            all_nodes.append(node)\n","        \n","        sorted_nodes = sorted(all_nodes, key=lambda node: node.score, reverse=True)[:top_k]\n","        return sorted_nodes"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Load Embedding Model & Benchmarks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T14:38:28.847209Z","iopub.status.busy":"2024-05-16T14:38:28.846888Z","iopub.status.idle":"2024-05-16T14:38:38.333823Z","shell.execute_reply":"2024-05-16T14:38:38.332945Z","shell.execute_reply.started":"2024-05-16T14:38:28.847181Z"},"trusted":true},"outputs":[],"source":["from llama_index.core import (\n","    Settings,\n","    VectorStoreIndex,\n","    Document,\n",")\n","\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from llama_index.retrievers.bm25 import BM25Retriever\n","\n","import pandas as pd"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T14:38:38.356741Z","iopub.status.busy":"2024-05-16T14:38:38.356437Z","iopub.status.idle":"2024-05-16T14:38:42.957868Z","shell.execute_reply":"2024-05-16T14:38:42.956861Z","shell.execute_reply.started":"2024-05-16T14:38:38.356716Z"},"trusted":true},"outputs":[],"source":["Settings.embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load context benchmark\n","benchmark = pd.read_csv(\"BX2_chicago.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load content benchmark + table summaries\n","# benchmark = pd.read_csv(\"BC1_chicago.csv\")\n","# summaries = pd.read_csv(\"row_summaries_chicago.csv\")"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Index Contexts/Summaries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T07:30:26.139379Z","iopub.status.busy":"2024-05-16T07:30:26.139035Z","iopub.status.idle":"2024-05-16T07:30:26.145184Z","shell.execute_reply":"2024-05-16T07:30:26.144209Z","shell.execute_reply.started":"2024-05-16T07:30:26.139354Z"},"trusted":true},"outputs":[],"source":["def create_context_documents(df):\n","    documents = []\n","    for idx in df.index:\n","        table = df[\"table\"][idx]\n","        answer = df[\"context\"][idx]\n","        document = Document(\n","            text=answer,\n","            metadata={\"table\": table},\n","            doc_id=f\"doc_'{table}'_{idx}\",\n","        )\n","        documents.append(document)\n","    return documents"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def create_content_documents(df):\n","    documents = []\n","    for idx in df.index:\n","        table = df[\"table\"][idx]\n","        table_summary = df[\"summary\"][idx]\n","        document = Document(\n","            text=table_summary,\n","            metadata={\"table\": table},\n","            doc_id=f\"doc_'{table}'_{idx}\",\n","        )\n","        documents.append(document)\n","    return documents"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","def get_sample_summaries(summaries: pd.DataFrame, sample_percentage=1):\n","    \"\"\"\n","    This is to randomly sample certain percentage of the summaries.\n","    The return value is the summaries but only for the sampled rows.\n","    \"\"\"\n","    # Prepare to sample summaries (category refers to the tables)\n","    category_counts = summaries[\"table\"].value_counts()\n","    sample_sizes = np.ceil(category_counts * sample_percentage).astype(int)\n","\n","    # Perform stratified sampling\n","    sampled_summaries = summaries.copy(deep=True)\n","    sampled_summaries[\"table_copy\"] = sampled_summaries[\"table\"]\n","    sampled_summaries = sampled_summaries.groupby(\"table_copy\", group_keys=False).apply(\n","        lambda x: x.sample(n=sample_sizes[x.name], random_state=42),\n","        include_groups=False,\n","    )\n","    return sampled_summaries.reset_index(drop=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create document for context benchmark\n","documents = create_context_documents(benchmark)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Create document for content benchmark\n","# documents = create_content_documents(summaries)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-16T07:30:26.987299Z","iopub.status.busy":"2024-05-16T07:30:26.987015Z","iopub.status.idle":"2024-05-16T07:32:34.079446Z","shell.execute_reply":"2024-05-16T07:32:34.078552Z","shell.execute_reply.started":"2024-05-16T07:30:26.987274Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["vector_index = VectorStoreIndex(documents)\n","print(\"Index created\")"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Evaluate System"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T07:32:34.082528Z","iopub.status.busy":"2024-05-16T07:32:34.082250Z","iopub.status.idle":"2024-05-16T07:32:34.088374Z","shell.execute_reply":"2024-05-16T07:32:34.087473Z","shell.execute_reply.started":"2024-05-16T07:32:34.082503Z"},"trusted":true},"outputs":[],"source":["from collections import defaultdict\n","\n","def convert_retrieved_data_to_tables_ranks(retrieved_data):\n","    # Convert all retrieved data to the format (table, rank)\n","    rank = 1\n","    prev_score = retrieved_data[0].get_score()\n","    tables_encountered = defaultdict(bool)\n","    tables_ranks = []\n","    for data in retrieved_data:\n","        table = data.id_.split(\"'\")[1]  # E.g., \"chicago_open_data/22u3-xenr\"\n","        if not tables_encountered[table]:\n","            if data.get_score() < prev_score:\n","                rank += 1\n","            tables_ranks.append((table, rank))\n","            prev_score = data.get_score()\n","            tables_encountered[table] = True\n","    return tables_ranks"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-16T07:32:34.089960Z","iopub.status.busy":"2024-05-16T07:32:34.089545Z","iopub.status.idle":"2024-05-16T07:32:34.097983Z","shell.execute_reply":"2024-05-16T07:32:34.097144Z","shell.execute_reply.started":"2024-05-16T07:32:34.089934Z"},"trusted":true},"outputs":[],"source":["import ast\n","def evaluate(retriever, benchmark_df, top_k=1):\n","    accuracy_sum = 0\n","    precision_at_1_sum = 0\n","    reciprocal_rank_sum = 0\n","    for i in range(len(benchmark_df)):\n","        query = benchmark_df[\"question\"][i]\n","        try:\n","            expected_tables = ast.literal_eval(benchmark_df[\"relevant_tables\"][i])\n","        except:\n","            expected_tables = [benchmark_df[\"table\"][i]]\n","        retrieved_data = retriever.retrieve(query, top_k)\n","        tables_ranks = convert_retrieved_data_to_tables_ranks(retrieved_data)\n","        for j, (table, rank) in enumerate(tables_ranks):\n","            if table in expected_tables:\n","                accuracy_sum += 1\n","                if rank == 1:\n","                    precision_at_1_sum += 1\n","                reciprocal_rank_sum += 1 / (j + 1)\n","                break\n","        if i % 100 == 0:  # Checkpoint\n","            print(i)\n","            print(\"Accuracy:\", accuracy_sum)\n","            print(\"Prec@1:\", precision_at_1_sum)\n","            print(\"Reciprocal Rank:\", reciprocal_rank_sum)\n","    return {\n","        \"accuracy\": accuracy_sum / benchmark_df.shape[0],\n","        \"Mean Precision@1\": precision_at_1_sum / benchmark_df.shape[0],\n","        \"MRR\": reciprocal_rank_sum / benchmark_df.shape[0],\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["vector_retriever = vector_index.as_retriever()\n","BM25_retriever = BM25Retriever.from_defaults(vector_index)\n","hybrid_retriever = HybridRetriever(BM25_retriever, vector_retriever)\n","result = evaluate(hybrid_retriever, benchmark, top_k=1)  # Adjust k\n","print(result)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4995818,"sourceId":8426657,"sourceType":"datasetVersion"},{"datasetId":5021434,"sourceId":8431643,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
