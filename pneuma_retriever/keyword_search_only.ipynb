{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/zp_more/project_data/pneuma/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import bm25s\n",
    "import Stemmer\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from benchmark_generator.context.utils.jsonl import read_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"fetaqa\"\n",
    "if dataset == \"chicago\":\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/chicago_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/chicago_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/chicago/contexts_chicago.jsonl\")\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_chicago_10K_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/chicago/bx_chicago.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_chicago_10K\"\n",
    "elif dataset == \"public\":\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/public_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/public_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/public/contexts_public.jsonl\")\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_public_bi_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/public/bx_public.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_public_bi\"\n",
    "elif dataset == \"chembl\":\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/chembl_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/chembl_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/chembl/contexts_chembl.jsonl\")\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_chembl_10K_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/chembl/bx_chembl.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_chembl_10K\"\n",
    "elif dataset == \"adventure\":\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/adventure_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/adventure_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/adventure/contexts_adventure.jsonl\")\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_adventure_works_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/adventure/bx_adventure.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_adventure_works\"\n",
    "elif dataset == \"fetaqa\":\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/fetaqa_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/fetaqa_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/fetaqa/contexts_fetaqa.jsonl\")\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_fetaqa_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/fetaqa/bx_fetaqa.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_fetaqa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing_keyword(\n",
    "    stemmer,\n",
    "    narration_contents: list[dict[str, str]],\n",
    "    contexts: list[dict[str, str]] = None,\n",
    "):\n",
    "    corpus_json = []\n",
    "    tables = sorted({content[\"table\"] for content in narration_contents})\n",
    "    for table in tables:\n",
    "        cols_descriptions = [content[\"summary\"] for content in narration_contents if content[\"table\"] == table]\n",
    "        for content_idx, content in enumerate(cols_descriptions):\n",
    "            corpus_json.append({\"text\": content, \"metadata\": {\"table\": f\"{table}_SEP_contents_{content_idx}\"}})\n",
    "\n",
    "        if contexts is not None:\n",
    "            filtered_contexts = [context[\"context\"] for context in contexts if context[\"table\"] == table]\n",
    "            for context_idx, context in enumerate(filtered_contexts):\n",
    "                corpus_json.append({\"text\": context, \"metadata\": {\"table\": f\"{table}_SEP_{context_idx}\"}})\n",
    "\n",
    "    corpus_text = [doc[\"text\"] for doc in corpus_json]\n",
    "    corpus_tokens = bm25s.tokenize(corpus_text, stopwords=\"en\", stemmer=stemmer, show_progress=False)\n",
    "\n",
    "    retriever = bm25s.BM25(corpus=corpus_json)\n",
    "    retriever.index(corpus_tokens, show_progress=False)\n",
    "    return retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer.Stemmer(\"english\")\n",
    "retriever = indexing_keyword(stemmer, narration_contents, contexts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_benchmark(\n",
    "    benchmark: list[dict[str,str]],\n",
    "    benchmark_type: str,\n",
    "    k: int,\n",
    "    retriever,\n",
    "    stemmer,\n",
    "    use_rephrased_questions=False\n",
    "):\n",
    "    hitrate_sum = 0\n",
    "    \n",
    "    def get_question_key(benchmark_type: str):\n",
    "        if benchmark_type == \"content\":\n",
    "            if not use_rephrased_questions:\n",
    "                question_key = \"question_from_sql_1\"\n",
    "            else:\n",
    "                question_key = \"question\"\n",
    "        else:\n",
    "            if not use_rephrased_questions:\n",
    "                question_key = \"question_bx1\"\n",
    "            else:\n",
    "                question_key = \"question_bx2\"\n",
    "        return question_key\n",
    "    question_key = get_question_key(benchmark_type)\n",
    "\n",
    "    questions = []\n",
    "    for data in benchmark:\n",
    "        questions.append(data[question_key])\n",
    "\n",
    "    for idx, datum in enumerate(tqdm(benchmark)):\n",
    "        answer_tables = datum[\"answer_tables\"]\n",
    "\n",
    "        query_tokens = bm25s.tokenize(questions[idx], stemmer=stemmer, show_progress=False)\n",
    "        results, scores = retriever.retrieve(query_tokens, k=k, show_progress=False)\n",
    "        bm25_res = (results, scores)\n",
    "\n",
    "        for result in results[0]:\n",
    "            table = result['metadata']['table'].split(\"_SEP_\")[0]\n",
    "            if table in answer_tables:\n",
    "                hitrate_sum += 1\n",
    "                break\n",
    "    print(f\"Hit Rate: {hitrate_sum/len(benchmark)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5961.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BC1\n",
    "evaluate_benchmark(\n",
    "    content_benchmark, \"content\", 1, retriever, stemmer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:00<00:00, 5946.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BC2\n",
    "evaluate_benchmark(\n",
    "    content_benchmark, \"content\", 1, retriever, stemmer, use_rephrased_questions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1020/1020 [00:00<00:00, 5118.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.7450980392156863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BX1\n",
    "evaluate_benchmark(\n",
    "    context_benchmark, \"context\", 1, retriever, stemmer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1020/1020 [00:00<00:00, 5235.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.6666666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BX2\n",
    "evaluate_benchmark(\n",
    "    context_benchmark, \"context\", 1, retriever, stemmer, use_rephrased_questions=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary-neo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
