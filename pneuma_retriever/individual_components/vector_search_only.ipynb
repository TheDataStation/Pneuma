{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/raid/p-storage/luthfibalaka_d2b65c57/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import chromadb\n",
    "import numpy as np\n",
    "import setproctitle\n",
    "\n",
    "setproctitle.setproctitle(\"python3.12\")\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import set_seed\n",
    "from chromadb.api.client import Client\n",
    "from chromadb.api.models.Collection import Collection\n",
    "from benchmark_generator.context.utils.jsonl import read_jsonl\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sentence_transformers.SentenceTransformer import SentenceTransformer\n",
    "\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "set_seed(42, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformer('../models/stella', local_files_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"chembl\"\n",
    "if dataset == \"chicago\":\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/chicago_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/chicago_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/chicago/contexts_chicago.jsonl\")\n",
    "\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_chicago_10K_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/chicago/bx_chicago.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_chicago_10K\"\n",
    "elif dataset == \"public\":\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/public_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/public_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/public/contexts_public.jsonl\")\n",
    "\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_public_bi_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/public/bx_public.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_public_bi\"\n",
    "elif dataset == \"chembl\":\n",
    "    row_contents = read_jsonl(\"../pneuma_summarizer/summaries/rows/chembl.jsonl\")\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/chembl_standard.jsonl\")\n",
    "    combine_contents = sorted(row_contents + std_contents, key=lambda x: x[\"table\"])\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/chembl/contexts_chembl.jsonl\")\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_chembl_10K_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/chembl/bx_chembl.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_chembl_10K\"\n",
    "elif dataset == \"adventure\":\n",
    "    overall_contents = read_jsonl(\"../pneuma_summarizer/summaries/overall/adventure_overall.jsonl\")\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/adventure_standard.jsonl\")\n",
    "    narration_contents = read_jsonl(\"../pneuma_summarizer/summaries/narrations/adventure_narrations.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/adventure/contexts_adventure.jsonl\")\n",
    "\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_adventure_works_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/adventure/bx_adventure.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_adventure_works\"\n",
    "elif dataset == \"fetaqa\":\n",
    "    row_contents = read_jsonl(\"../pneuma_summarizer/summaries/rows/fetaqa.jsonl\")\n",
    "    overall_contents = read_jsonl(\"../pneuma_summarizer/summaries/overall/fetaqa_overall.jsonl\")\n",
    "    # row_contents = read_jsonl(\"../pneuma_summarizer/summaries/rows-old/fetaqa_rows.jsonl\")\n",
    "    std_contents = read_jsonl(\"../pneuma_summarizer/summaries/standard/fetaqa_standard.jsonl\")\n",
    "    contexts = read_jsonl(\"../data_src/benchmarks/context/fetaqa/contexts_fetaqa.jsonl\")\n",
    "    content_benchmark = read_jsonl(\"../data_src/benchmarks/content/pneuma_fetaqa_questions_annotated.jsonl\")\n",
    "    context_benchmark = read_jsonl(\"../data_src/benchmarks/context/fetaqa/bx_fetaqa.jsonl\")\n",
    "    path = \"../data_src/tables/pneuma_fetaqa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexing_vector(\n",
    "    client: Client,\n",
    "    embedding_model: SentenceTransformer,\n",
    "    std_contents: list[dict[str, str]],\n",
    "    contexts: list[dict[str, str]] = None,\n",
    "    collection_name = \"benchmark\",\n",
    "    reindex = False,\n",
    "):\n",
    "    documents = []\n",
    "    metadatas = []\n",
    "    ids = []\n",
    "\n",
    "    if not reindex:\n",
    "        try:\n",
    "            collection = client.get_collection(collection_name)\n",
    "            return collection\n",
    "        except:\n",
    "            pass\n",
    "    try:\n",
    "        client.delete_collection(collection_name)\n",
    "    except:\n",
    "        pass\n",
    "    collection = client.create_collection(\n",
    "        name=collection_name,\n",
    "        metadata={\"hnsw:space\": \"cosine\", \"hnsw:random_seed\": 42}\n",
    "    )\n",
    "\n",
    "    tables = sorted({content[\"table\"] for content in std_contents})\n",
    "    for table in tables:\n",
    "        cols = [content[\"summary\"] for content in std_contents if content[\"table\"] == table]\n",
    "        for content_idx, content in enumerate(cols):\n",
    "            documents.append(content)\n",
    "            metadatas.append({\"table\": f\"{table}_SEP_contents_{content_idx}\"})\n",
    "            ids.append(f\"{table}_SEP_contents_{content_idx}\")\n",
    "\n",
    "        if contexts is not None:\n",
    "            filtered_contexts = [context[\"context\"] for context in contexts if context[\"table\"] == table]\n",
    "            for context_idx, context in enumerate(filtered_contexts):\n",
    "                documents.append(context)\n",
    "                metadatas.append({\"table\": f\"{table}_SEP_{context_idx}\"})\n",
    "                ids.append(f\"{table}_SEP_{context_idx}\")\n",
    "\n",
    "    for i in range(0, len(documents), 30000):\n",
    "        try:\n",
    "            raise ValueError()\n",
    "            embeddings = np.loadtxt(\n",
    "                f\"TEMP-{i}.txt\"\n",
    "            )\n",
    "        except:\n",
    "            embeddings = embedding_model.encode(\n",
    "                documents[i:i+30000],\n",
    "                batch_size=100,\n",
    "                show_progress_bar=True,\n",
    "                device=\"cuda\"\n",
    "            )\n",
    "            # np.savetxt(\n",
    "            #     f\"TEMP-{i}.txt\", embeddings\n",
    "            # )\n",
    "\n",
    "        collection.add(\n",
    "            embeddings=[embed.tolist() for embed in embeddings],\n",
    "            metadatas=metadatas[i:i+30000],\n",
    "            documents=documents[i:i+30000],\n",
    "            ids=ids[i:i+30000],\n",
    "        )\n",
    "    return collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_contents = row_contents + overall_contents\n",
    "# combine_contents.sort(key=lambda x: x[\"table\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "try:\n",
    "    shutil.rmtree(f\"index-{dataset}-TEMP\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/5 [00:00<?, ?it/s]We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n",
      "Batches: 100%|██████████| 5/5 [00:13<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing time: 13.600780963897705 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "client = chromadb.PersistentClient(f\"index-{dataset}-TEMP\")\n",
    "collection = indexing_vector(client, embedding_model, combine_contents, None)\n",
    "end = time.time()\n",
    "print(f\"Indexing time: {end-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_benchmark(\n",
    "    benchmark: list[dict[str,str]],\n",
    "    benchmark_type: str,\n",
    "    k: int,\n",
    "    embedding_model: SentenceTransformer,\n",
    "    collection: Collection,\n",
    "    use_rephrased_questions=False\n",
    "):\n",
    "    start = time.time()\n",
    "    hitrate_sum = 0\n",
    "    wrong_questions = []\n",
    "    def get_question_key(benchmark_type: str):\n",
    "        if benchmark_type == \"content\":\n",
    "            if not use_rephrased_questions:\n",
    "                question_key = \"question_from_sql_1\"\n",
    "            else:\n",
    "                question_key = \"question\"\n",
    "        else:\n",
    "            if not use_rephrased_questions:\n",
    "                question_key = \"question_bx1\"\n",
    "            else:\n",
    "                question_key = \"question_bx2\"\n",
    "        return question_key\n",
    "    question_key = get_question_key(benchmark_type)\n",
    "\n",
    "    questions = []\n",
    "    for data in benchmark:\n",
    "        questions.append(data[question_key])\n",
    "    try:\n",
    "        embed_questions = np.loadtxt(\n",
    "            f\"embeddings/embed-{dataset}-questions-{benchmark_type}-{use_rephrased_questions}.txt\"\n",
    "        )\n",
    "    except:\n",
    "        embed_questions = embedding_model.encode(questions, batch_size=64, show_progress_bar=True)\n",
    "        np.savetxt(\n",
    "            f\"embeddings/embed-{dataset}-questions-{benchmark_type}-{use_rephrased_questions}.txt\",\n",
    "            embed_questions,\n",
    "        )\n",
    "    embed_questions = [embed.tolist() for embed in embed_questions]\n",
    "\n",
    "    for idx, datum in enumerate(tqdm(benchmark)):\n",
    "        answer_tables = datum[\"answer_tables\"]\n",
    "        vec_res = collection.query(\n",
    "            query_embeddings=[embed_questions[idx]],\n",
    "            n_results=k\n",
    "        )\n",
    "        before = hitrate_sum\n",
    "        for res in vec_res['ids'][0]:\n",
    "            table = res.split(\"_SEP_\")[0]\n",
    "            if table in answer_tables:\n",
    "                hitrate_sum += 1\n",
    "                break\n",
    "        if before == hitrate_sum:\n",
    "            # print(f\"Question: {questions[idx]}\")\n",
    "            # print(f\"Answer tables: {answer_tables[:50]}\")\n",
    "            # print(f\"Actual table: {vec_res[\"documents\"][0][0]}\")\n",
    "            # if len(wrong_questions) == 2:\n",
    "            #     raise ValueError()\n",
    "            wrong_questions.append(idx)\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Hit Rate: {hitrate_sum/len(benchmark) * 100}\")\n",
    "    print(f\"Benchmarking Time: {end - start} seconds\")\n",
    "    print(f\"Wrongly answered questions: {wrong_questions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 351.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 42.199999999999996\n",
      "Benchmarking Time: 3.2331340312957764 seconds\n",
      "Wrongly answered questions: [1, 2, 4, 5, 6, 7, 8, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 31, 32, 33, 34, 35, 36, 38, 39, 40, 41, 42, 43, 46, 48, 52, 53, 55, 56, 57, 59, 60, 62, 65, 69, 75, 76, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 101, 102, 103, 105, 107, 110, 114, 115, 116, 118, 120, 121, 122, 123, 125, 128, 129, 130, 131, 133, 134, 135, 136, 138, 141, 142, 143, 146, 147, 148, 149, 160, 161, 164, 165, 172, 173, 174, 177, 178, 180, 182, 184, 187, 190, 192, 194, 195, 196, 199, 200, 201, 210, 211, 212, 213, 215, 216, 217, 218, 220, 221, 222, 223, 230, 231, 232, 234, 238, 239, 240, 244, 245, 246, 247, 250, 251, 253, 254, 257, 258, 259, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 276, 277, 280, 282, 284, 288, 290, 291, 293, 297, 298, 299, 300, 301, 303, 305, 306, 307, 309, 310, 311, 312, 315, 318, 320, 321, 322, 323, 325, 327, 328, 329, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 343, 344, 345, 346, 347, 349, 353, 354, 355, 356, 357, 358, 362, 364, 365, 367, 370, 374, 375, 376, 378, 380, 383, 385, 386, 387, 389, 391, 392, 393, 394, 395, 396, 398, 404, 405, 406, 409, 410, 411, 414, 415, 416, 417, 418, 420, 421, 429, 430, 433, 435, 436, 437, 440, 443, 448, 449, 456, 457, 458, 460, 461, 462, 466, 468, 469, 470, 472, 473, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 497, 498, 499, 505, 507, 509, 510, 511, 512, 514, 519, 521, 522, 524, 528, 529, 530, 532, 534, 535, 536, 537, 538, 539, 541, 542, 543, 545, 546, 547, 548, 549, 551, 553, 554, 555, 556, 557, 558, 560, 565, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 582, 588, 590, 591, 593, 594, 595, 596, 597, 598, 601, 604, 605, 606, 608, 615, 616, 617, 618, 619, 624, 626, 627, 630, 632, 633, 635, 636, 637, 644, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 664, 666, 667, 668, 669, 670, 678, 680, 681, 682, 684, 685, 686, 687, 689, 690, 693, 694, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 709, 710, 716, 718, 719, 720, 721, 722, 723, 724, 725, 726, 728, 729, 731, 732, 734, 739, 740, 741, 742, 743, 745, 746, 747, 749, 757, 758, 764, 765, 767, 768, 769, 771, 776, 777, 781, 783, 784, 788, 789, 790, 793, 794, 795, 796, 798, 800, 801, 802, 803, 805, 811, 821, 822, 823, 826, 827, 829, 830, 837, 839, 841, 842, 844, 845, 846, 847, 848, 849, 850, 857, 858, 859, 860, 861, 862, 865, 866, 867, 868, 869, 872, 873, 874, 878, 879, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 894, 895, 896, 897, 898, 899, 900, 901, 903, 906, 909, 910, 911, 916, 917, 921, 922, 924, 925, 927, 929, 931, 932, 935, 936, 944, 945, 947, 948, 949, 950, 951, 953, 954, 956, 957, 958, 959, 962, 963, 964, 966, 967, 969, 970, 971, 973, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 987, 990, 991, 992, 993, 994, 997, 999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BC1\n",
    "evaluate_benchmark(\n",
    "    content_benchmark, \"content\", 1, embedding_model, collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 348.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 40.1\n",
      "Benchmarking Time: 3.256103515625 seconds\n",
      "Wrongly answered questions: [1, 2, 3, 4, 5, 6, 7, 8, 11, 12, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 46, 48, 49, 51, 52, 53, 55, 56, 59, 62, 65, 66, 67, 69, 73, 74, 75, 76, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 100, 102, 103, 105, 106, 107, 110, 111, 113, 115, 117, 119, 120, 122, 123, 124, 125, 127, 128, 129, 130, 131, 133, 135, 136, 142, 143, 144, 146, 147, 148, 154, 157, 158, 159, 160, 161, 162, 164, 168, 173, 174, 175, 176, 177, 178, 179, 180, 182, 184, 186, 187, 188, 189, 190, 194, 195, 196, 198, 199, 203, 204, 209, 210, 211, 212, 213, 217, 218, 220, 221, 222, 223, 228, 229, 230, 231, 234, 236, 237, 239, 247, 251, 253, 254, 255, 256, 257, 258, 259, 262, 264, 265, 266, 267, 268, 271, 272, 273, 276, 277, 279, 280, 282, 284, 288, 290, 291, 293, 294, 297, 298, 299, 302, 303, 307, 308, 310, 311, 312, 314, 315, 316, 318, 319, 320, 321, 322, 323, 325, 327, 328, 329, 331, 332, 333, 335, 336, 338, 339, 340, 342, 343, 344, 347, 348, 349, 353, 356, 358, 360, 361, 362, 365, 366, 367, 370, 373, 374, 375, 376, 378, 383, 385, 386, 387, 391, 392, 394, 395, 396, 399, 400, 401, 403, 404, 405, 409, 410, 411, 417, 418, 420, 425, 426, 430, 435, 436, 437, 440, 441, 442, 443, 444, 445, 447, 448, 454, 458, 459, 460, 462, 463, 464, 466, 468, 469, 470, 471, 473, 477, 478, 479, 480, 481, 482, 484, 486, 487, 488, 489, 490, 491, 492, 493, 494, 497, 498, 499, 502, 505, 507, 509, 510, 512, 514, 515, 518, 519, 521, 524, 525, 526, 527, 529, 530, 531, 532, 533, 534, 535, 537, 538, 539, 540, 541, 542, 543, 545, 546, 548, 549, 550, 551, 553, 554, 560, 561, 565, 566, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 582, 585, 590, 591, 592, 593, 594, 595, 596, 598, 601, 605, 608, 609, 610, 612, 615, 616, 617, 618, 621, 624, 627, 629, 630, 631, 632, 633, 634, 635, 636, 640, 642, 643, 644, 645, 646, 647, 648, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 664, 665, 666, 667, 668, 669, 670, 671, 672, 678, 679, 680, 681, 684, 685, 687, 688, 689, 690, 693, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 707, 709, 715, 716, 718, 719, 720, 721, 722, 723, 725, 727, 730, 731, 732, 734, 737, 739, 740, 741, 742, 744, 745, 746, 747, 749, 751, 758, 760, 761, 762, 765, 768, 769, 770, 774, 775, 776, 777, 778, 779, 781, 783, 784, 785, 786, 787, 790, 792, 793, 794, 795, 796, 797, 798, 801, 802, 803, 805, 806, 815, 826, 827, 828, 829, 836, 837, 838, 839, 840, 841, 842, 843, 845, 846, 848, 850, 858, 860, 861, 865, 866, 867, 872, 874, 875, 876, 878, 879, 880, 881, 882, 883, 884, 885, 888, 889, 890, 892, 894, 895, 896, 897, 898, 899, 900, 902, 903, 906, 909, 910, 911, 916, 918, 919, 921, 924, 927, 931, 932, 933, 935, 936, 937, 940, 944, 945, 947, 949, 951, 952, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 969, 971, 973, 975, 976, 977, 978, 979, 980, 982, 983, 984, 985, 986, 987, 988, 990, 991, 992, 997, 999]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# BC2\n",
    "evaluate_benchmark(\n",
    "    content_benchmark, \"content\", 1, embedding_model, collection, use_rephrased_questions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BX1\n",
    "evaluate_benchmark(\n",
    "    context_benchmark, \"context\", 1, embedding_model, collection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BX2\n",
    "evaluate_benchmark(\n",
    "    context_benchmark, \"context\", 1, embedding_model, collection, use_rephrased_questions=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summary-neo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
