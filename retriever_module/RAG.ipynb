{"cells":[{"cell_type":"markdown","metadata":{},"source":["# RAG"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Install Packages & Load Models"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-26T01:55:01.697031Z","iopub.status.busy":"2024-05-26T01:55:01.696046Z","iopub.status.idle":"2024-05-26T01:55:50.104244Z","shell.execute_reply":"2024-05-26T01:55:50.103034Z","shell.execute_reply.started":"2024-05-26T01:55:01.696987Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# Uncomment these lines to install necessary packages\n","# !pip install llama-index-core\n","# !pip install llama-index-llms-huggingface\n","# !pip install llama-index-embeddings-huggingface"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment these lines if required to choose GPU\n","import os\n","import setproctitle\n","os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","setproctitle.setproctitle(\"python\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T01:55:50.107128Z","iopub.status.busy":"2024-05-26T01:55:50.106719Z","iopub.status.idle":"2024-05-26T01:56:00.296029Z","shell.execute_reply":"2024-05-26T01:56:00.294939Z","shell.execute_reply.started":"2024-05-26T01:55:50.107090Z"},"trusted":true},"outputs":[],"source":["from llama_index.core import (\n","    Settings,\n","    VectorStoreIndex,\n","    Document,\n",")\n","\n","from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n","from llama_index.llms.huggingface import HuggingFaceLLM\n","from llama_index.core import PromptTemplate\n","\n","import pandas as pd\n","import torch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T01:56:00.297647Z","iopub.status.busy":"2024-05-26T01:56:00.297124Z","iopub.status.idle":"2024-05-26T01:56:04.864155Z","shell.execute_reply":"2024-05-26T01:56:04.863038Z","shell.execute_reply.started":"2024-05-26T01:56:00.297619Z"},"trusted":true},"outputs":[],"source":["Settings.embed_model = HuggingFaceEmbedding(\n","    model_name=\"BAAI/bge-small-en-v1.5\"\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load huggingface access token (create one if not yet available) to access gated model\n","!export HUGGINGFACE_TOKEN=\"TODO\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query_wrapper_prompt = PromptTemplate(\"[INST] {query_str} [/INST]\")  # Specific to Mistral-7B\n","\n","Settings.llm = HuggingFaceLLM(\n","    context_window=32768,\n","    max_new_tokens=512,\n","    query_wrapper_prompt=query_wrapper_prompt,\n","    generate_kwargs={\"do_sample\": False, \"pad_token_id\": 2},\n","    model_kwargs={\n","        \"torch_dtype\": torch.bfloat16,\n","    },\n","    tokenizer_name=\"mistralai/Mistral-7B-Instruct-v0.3\",\n","    model_name=\"mistralai/Mistral-7B-Instruct-v0.3\",\n","    device_map=\"auto\",\n","    tokenizer_kwargs={\"max_length\": 32768},\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T01:53:32.632496Z","iopub.status.busy":"2024-05-26T01:53:32.632117Z","iopub.status.idle":"2024-05-26T01:53:32.657536Z","shell.execute_reply":"2024-05-26T01:53:32.656670Z","shell.execute_reply.started":"2024-05-26T01:53:32.632465Z"},"trusted":true},"outputs":[],"source":["benchmark = pd.read_csv(\"BX1_chicago_corrected.csv\")\n","# summaries = pd.read_csv(\"BC1_chicago.csv\")  # Necessary for content benchmarks only\n","benchmark.head()"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Index Documents"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T01:53:36.427680Z","iopub.status.busy":"2024-05-26T01:53:36.427296Z","iopub.status.idle":"2024-05-26T01:53:36.437748Z","shell.execute_reply":"2024-05-26T01:53:36.436709Z","shell.execute_reply.started":"2024-05-26T01:53:36.427653Z"},"trusted":true},"outputs":[],"source":["def create_content_documents(df):\n","    # Create documents to index (for content benchmarks)\n","    documents = []\n","    for idx in df.index:\n","        table = df[\"table\"][idx]\n","        table_summary = df[\"summary\"][idx]\n","        document = Document(\n","            text=table_summary,\n","            metadata={\"table\": table},\n","            doc_id=f\"doc_'{table}'_{idx}\",\n","        )\n","        documents.append(document)\n","    return documents\n","\n","def create_context_documents(df):\n","    # Create documents to index (for context benchmarks)\n","    documents = []\n","    for idx in df.index:\n","        table = df[\"table\"][idx]\n","        answer = df[\"context\"][idx]\n","        document = Document(\n","            text=answer,\n","            metadata={\"table\": table},\n","            doc_id=f\"doc_{idx}\",\n","        )\n","        documents.append(document)\n","    return documents"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get documents for context benchmarks\n","documents = create_context_documents(benchmark)\n","\n","# Get documents for content benchmarks\n","# documents = create_context_documents(summaries)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.execute_input":"2024-05-26T01:53:39.036855Z","iopub.status.busy":"2024-05-26T01:53:39.036136Z","iopub.status.idle":"2024-05-26T01:53:56.661310Z","shell.execute_reply":"2024-05-26T01:53:56.660361Z","shell.execute_reply.started":"2024-05-26T01:53:39.036824Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["vector_index = VectorStoreIndex(documents);\n","print(\"Index created\")"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Evaluate RAG"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T01:53:23.922897Z","iopub.status.busy":"2024-05-26T01:53:23.921988Z","iopub.status.idle":"2024-05-26T01:53:23.928090Z","shell.execute_reply":"2024-05-26T01:53:23.927148Z","shell.execute_reply.started":"2024-05-26T01:53:23.922852Z"},"trusted":true},"outputs":[],"source":["def get_query(question: str, k: int):\n","    # Instruction for the LLM to return relevant dataset(s) in ranked format\n","    return f\"\"\"{question} Provide your response in the following format:\n","- Datasets: {k} datasets that are relevant to the query (ordered from the most relevant) in a valid Python list format.\n","- Explanation: Explain briefly why these datasets are relevant to the query.\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import json, re\n","\n","def extract_and_format_datasets(input_string: str) -> list[str]:\n","    try:\n","        # Extract the datasets string\n","        datasets_string = input_string.split('- Datasets: ')[1].split(']')[0] + ']'\n","        \n","        # Check if the datasets string is already a valid JSON format\n","        try:\n","            datasets_list = json.loads(datasets_string)\n","        except json.JSONDecodeError:\n","            # If not, format it to be a valid JSON list\n","            datasets_string = re.sub(r'(\\w+/\\w+-\\w+)', r'\"\\1\"', datasets_string)\n","            datasets_list = json.loads(datasets_string)\n","        \n","        # Flatten the list if it is nested (i.e., contains lists within a list)\n","        if isinstance(datasets_list, list) and all(isinstance(i, list) for i in datasets_list):\n","            datasets_list = [item for sublist in datasets_list for item in sublist]\n","        \n","        return datasets_list\n","    except:\n","        # Worst case scenario\n","        return []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T01:51:57.708097Z","iopub.status.busy":"2024-05-26T01:51:57.707820Z","iopub.status.idle":"2024-05-26T01:51:57.792204Z","shell.execute_reply":"2024-05-26T01:51:57.791396Z","shell.execute_reply.started":"2024-05-26T01:51:57.708072Z"},"trusted":true},"outputs":[],"source":["import ast\n","import re\n","\n","def evaluate_context_benchmark(benchmark, query_engine, k):\n","    accuracy_sum = 0\n","    precision_at_1_sum = 0\n","    reciprocal_rank_sum = 0\n","    for i in range(len(benchmark)):\n","        question = benchmark[\"question\"][i]\n","        expected_datasets = ast.literal_eval(benchmark[\"relevant_tables\"][i])\n","        query = get_query(question, k)\n","        query_response = query_engine.query(query)\n","        datasets = extract_and_format_datasets(str(query_response))\n","\n","        print(datasets)\n","        for rank, dataset in enumerate(datasets):\n","            if dataset in expected_datasets:\n","                accuracy_sum += 1\n","                if rank == 0:\n","                    precision_at_1_sum += 1\n","                reciprocal_rank_sum += (1 / (rank + 1))\n","                break\n","        if i % 10 == 0:  # Checkpointing\n","            print(\"=\" * 50)\n","            print(f\"Index: {i}\")\n","            print(accuracy_sum)\n","            print(precision_at_1_sum)\n","            print(reciprocal_rank_sum)\n","            print(\"=\" * 50)\n","    return {\n","        \"accuracy\": accuracy_sum/len(benchmark),\n","        \"Mean Precision@1\": precision_at_1_sum/len(benchmark),\n","        \"MRR\": reciprocal_rank_sum/len(benchmark),\n","    }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-26T01:51:57.793514Z","iopub.status.busy":"2024-05-26T01:51:57.793214Z","iopub.status.idle":"2024-05-26T01:52:01.755454Z","shell.execute_reply":"2024-05-26T01:52:01.753335Z","shell.execute_reply.started":"2024-05-26T01:51:57.793490Z"},"trusted":true},"outputs":[],"source":["import time\n","start_time = time.time()\n","result = evaluate_context_benchmark(\n","    benchmark,\n","    vector_index.as_query_engine(similarity_top_k=10),  # Adjust k\n","    10,\n",")\n","end_time = time.time()\n","print(f\"Total time elapsed: {end_time-start_time} seconds\")\n","print(f\"Result: {result}\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4815872,"sourceId":8162898,"sourceType":"datasetVersion"},{"datasetId":4992603,"sourceId":8392827,"sourceType":"datasetVersion"},{"datasetId":4995818,"sourceId":8426657,"sourceType":"datasetVersion"}],"dockerImageVersionId":30665,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":4}
