{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pneuma-Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Load Packages and LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select GPU (if necessary)\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "import setproctitle\n",
    "setproctitle.setproctitle(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import warnings\n",
    "import random\n",
    "import math\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from benchmark_generator.context.utils.pipeline_initializer import initialize_pipeline\n",
    "from benchmark_generator.context.utils.prompting_interface import prompt_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "pipe = initialize_pipeline(\"meta-llama/Meta-Llama-3-8B-Instruct\", torch.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_info_from_df(df: pd.DataFrame, row_idx=0):\n",
    "    col = \"col: \" + \" | \".join(df.columns)\n",
    "    row = \"row: \" + \" | \".join(df.iloc[row_idx].astype(str).str.strip())\n",
    "    return col + \"\\n\" + row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_summary_prompt(selected_summaries: list[str]):\n",
    "    return f\"\"\"Given these pieces of information regarding some row(s) of a dataset:\n",
    "/*\n",
    "{\"; \".join(selected_summaries)}\n",
    "*/\n",
    "Guess reasonably what this dataset is about. Respond briefly.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dtype_check_prompt(col_name: str, stats: str):\n",
    "    \"\"\"Get prompt to check if an integer column is actually ID/categorical or not\"\"\"\n",
    "    return f\"\"\"Do you think a column named {col_name}, which has values such as {stats}, is an identifier or categorical column? Begin your argument with yes/no.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_summary_prompt(dataset_info: str, col_name: str, col_stats: str):\n",
    "    return f\"\"\"Given the following description of a dataset and statistics about column {col_name} of the dataset, generate a short paragraph about the column statistics while considering the description:\n",
    "Dataset description = \"{dataset_info}\"\n",
    "Column statistics = \"{col_stats}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_summary_prompt(row_info: str):\n",
    "    return f\"\"\"Given this row of a dataset:\n",
    "/*\n",
    "{row_info}\n",
    "*/\n",
    "Summarize it comprehensively into a single paragraph without adding any external information.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_similarity(row1: pd.Series, row2: pd.Series):\n",
    "    \"\"\"Compute how many columns are the same between two rows\"\"\"\n",
    "    similarity = (row1 == row2).mean()\n",
    "    return similarity\n",
    "\n",
    "def remove_similar_rows(df: pd.DataFrame, threshold=0.9):\n",
    "    \"\"\"Remove rows that have a similarity greater than or equal to the threshold\"\"\"\n",
    "    to_drop = set()  # Set of indices to drop\n",
    "    for i in range(len(df)):\n",
    "        if i in to_drop:\n",
    "            continue\n",
    "        for j in range(i + 1, len(df)):\n",
    "            if j in to_drop:\n",
    "                continue\n",
    "            if row_similarity(df.iloc[i], df.iloc[j]) >= threshold:\n",
    "                to_drop.add(j)\n",
    "    return df.drop(to_drop).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_numerical_cols(df: pd.DataFrame, s=5):\n",
    "    \"\"\"\n",
    "    Return two lists: numerical and categorical columns\n",
    "\n",
    "    Side effect: int columns that are actually categorical will be converted to object data type\n",
    "    \"\"\"\n",
    "    to_be_checked: list[str] = []\n",
    "    num_cols: list[str] = []\n",
    "    cat_cols: list[str] = []\n",
    "    for col in df.columns:\n",
    "        if (df[col].dtype == \"int64\"):\n",
    "            # Check whether an integer column is actually categorical\n",
    "            to_be_checked.append(col)\n",
    "        elif (df[col].dtype == \"float64\"):\n",
    "            num_cols.append(col)\n",
    "        else:\n",
    "            cat_cols.append(col)\n",
    "\n",
    "    for col in to_be_checked:\n",
    "        if s <= len(df):\n",
    "            col_stats = f\"{list(df[col])} ({len(df[col].unique())}/{len(df[col])} unique values)\"\n",
    "        else:\n",
    "            col_stats = f\"{list(df[col].sample(s, random_state=42))} ({len(df[col].unique())}/{len(df[col])} unique values)\"\n",
    "        prompt = get_dtype_check_prompt(col, col_stats)\n",
    "        dtype_ans = prompt_pipeline(\n",
    "            pipe,\n",
    "            [{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=None,\n",
    "            top_p=None,\n",
    "            max_new_tokens=5\n",
    "        )[-1][\"content\"]\n",
    "        if (dtype_ans.strip().lower().startswith(\"yes\") or dtype_ans.strip().lower().startswith(\"**yes\")):\n",
    "            cat_cols.append(col)\n",
    "            df[col] = df[col].astype(object)\n",
    "    return (num_cols, cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Produce Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_summaries(sampled_df: pd.DataFrame):\n",
    "    row_summaries: list[str] = []\n",
    "    for i in range(len(sampled_df)):\n",
    "        print(f\"Summarizing row {i} of sampled_df\")\n",
    "        row_info = get_row_info_from_df(sampled_df, i)\n",
    "        prompt = get_row_summary_prompt(row_info)\n",
    "        row_summary = prompt_pipeline(\n",
    "            pipe,\n",
    "            [{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=None,\n",
    "            top_p=None,\n",
    "            max_new_tokens=400,\n",
    "        )[-1][\"content\"]\n",
    "        row_summaries.append(row_summary)\n",
    "    return row_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_summary(row_summaries: list[str]) -> str:\n",
    "    \"\"\"Summarize overall meaning of a table\"\"\"\n",
    "    random.seed(42)\n",
    "    sample_size = min(3, len(row_summaries))\n",
    "    selected_summaries = random.sample(row_summaries, sample_size)\n",
    "\n",
    "    summary_prompt = get_table_summary_prompt(selected_summaries)\n",
    "    table_summary = prompt_pipeline(\n",
    "        pipe,\n",
    "        [{\"role\": \"user\", \"content\": summary_prompt}],\n",
    "        temperature=None,\n",
    "        top_p=None,\n",
    "        max_new_tokens=150,\n",
    "    )[-1][\"content\"]\n",
    "    return table_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_columns_summaries(\n",
    "    table_summary,\n",
    "    df: pd.DataFrame,\n",
    "    num_cols: list[str],\n",
    "):\n",
    "    num_cols_summaries: list[str] = []\n",
    "    for num_col in num_cols:\n",
    "        print(f\"==> Col {num_col}\")\n",
    "        col_stats = \"; \".join(\n",
    "            [f\"{index}: {value}\" for index, value in df[num_col].describe().items()]\n",
    "        )\n",
    "        prompt = get_col_summary_prompt(table_summary, num_col, col_stats)\n",
    "        num_col_summary = prompt_pipeline(\n",
    "            pipe,\n",
    "            [{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=None,\n",
    "            top_p=None,\n",
    "            max_new_tokens=200,\n",
    "        )[-1][\"content\"]\n",
    "        num_cols_summaries.append(num_col_summary)\n",
    "    return num_cols_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat_columns_summaries(\n",
    "    table_summary: str,\n",
    "    df: pd.DataFrame,\n",
    "    cat_cols: list[str],\n",
    "    show_unique_cat_threshold=10\n",
    "):\n",
    "    cat_cols_summaries: list[str] = []\n",
    "    for cat_col in cat_cols:\n",
    "        print(f\"==> Col {cat_col}\", flush=True)\n",
    "        col_stats = \"; \".join(\n",
    "            [f\"{index}: {value}\" for index, value in df[cat_col].describe().items()]\n",
    "        )\n",
    "\n",
    "        if len(df[cat_col].unique()) <= show_unique_cat_threshold:\n",
    "            # Show unique values as well if less than the threshold\n",
    "            col_stats += f\"; categories: {df[cat_col].unique()}\"\n",
    "\n",
    "        prompt = get_col_summary_prompt(table_summary, cat_col, col_stats)\n",
    "        cat_col_summary = prompt_pipeline(\n",
    "            pipe,\n",
    "            [{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=None,\n",
    "            top_p=None,\n",
    "            max_new_tokens=200,\n",
    "        )[-1][\"content\"]\n",
    "        cat_cols_summaries.append(cat_col_summary)\n",
    "    return cat_cols_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_summaries(\n",
    "    df: pd.DataFrame,\n",
    "    row_summaries_percentage=0.05,\n",
    "):\n",
    "    all_summaries: list[str] = []\n",
    "    print(\"Start summarizing table\")\n",
    "\n",
    "    print(\"Summarizing some rows\")\n",
    "    result_df: pd.DataFrame = remove_similar_rows(df, threshold=0.9)\n",
    "    sampled_df = result_df.sample(\n",
    "        math.ceil(row_summaries_percentage * len(result_df)), random_state=42\n",
    "    ).reset_index(drop=True)\n",
    "    row_summaries = get_row_summaries(sampled_df)\n",
    "\n",
    "    print(\"Summarizing the overall table\")\n",
    "    table_summary = get_table_summary(row_summaries)\n",
    "\n",
    "    num_cols, cat_cols = get_categorical_numerical_cols(df)\n",
    "\n",
    "    print(\"Summarizing the numerical cols\")\n",
    "    num_cols_summaries = get_num_columns_summaries(table_summary, df, num_cols)\n",
    "\n",
    "    print(\"Summarizing the categorical cols\")\n",
    "    cat_cols_summaries = get_cat_columns_summaries(table_summary, df, cat_cols)\n",
    "\n",
    "    all_summaries = row_summaries + [table_summary] + num_cols_summaries + cat_cols_summaries\n",
    "    return all_summaries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
